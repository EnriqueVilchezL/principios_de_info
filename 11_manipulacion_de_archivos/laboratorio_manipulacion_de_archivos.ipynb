{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0079d21",
   "metadata": {},
   "source": [
    "**Ejercicio 1**\n",
    "\n",
    "En este ejercicio se trabajará con **convoluciones**, operaciones fundamentales en procesamiento de imágenes y visión por computadora. Aunque nunca se haya trabajado con imágenes, los conceptos son accesibles para alguien con conocimientos de programación.\n",
    "\n",
    "---\n",
    "\n",
    "*¿Qué es una convolución?*\n",
    "\n",
    "\n",
    "La **convolución** es una operación matemática que permite transformar una imagen para **resaltar ciertas características**, como bordes, esquinas o texturas.  \n",
    "\n",
    "- Una **imagen** puede considerarse como una **matriz de números**, donde cada número representa la intensidad de un píxel (en blanco y negro) o un color (en imágenes a color). En este caso, vamos a trabajar solo con imágenes en escala de grises, por lo que la imágen es una matriz 2D donde cada pixel es una celda, con un valor entre 0 y 255 que representa su color. \n",
    "- Un **kernel** (o filtro) es otra matriz de números, de menor tamaño, que se utiliza para \"transformar\" la imagen original.  \n",
    "\n",
    "El procedimiento de la convolución consiste en:\n",
    "\n",
    "1. Colocar el kernel sobre una sección de la imagen.  \n",
    "2. Multiplicar cada número del kernel por el número correspondiente de la imagen.  \n",
    "3. Sumar todos los resultados.  \n",
    "4. Colocar ese número en la posición central de la imagen de salida.  \n",
    "5. Repetir el proceso desplazando el kernel sobre toda la imagen.  \n",
    "\n",
    "En otras palabras, el kernel “desliza” sobre la imagen y calcula **una combinación ponderada de los píxeles vecinos**.  \n",
    "\n",
    "Puede ver este video corto para entender mejor la operación: [Video de convolución](https://www.youtube.com/shorts/-D5yuIHciO0).\n",
    "\n",
    "Esta página interactiva muestra cómo moviendo su cursor sobre la imágen, se ve el resultado de aplicar una convolución con cierto kernel a una zona de la imágen: [Setosa](https://setosa.io/ev/image-kernels/)\n",
    "\n",
    "---\n",
    "\n",
    "*Matemáticamente*\n",
    "\n",
    "\n",
    "Sea $I$ la imagen original, con píxeles $p_{fila,columna}$, y $K$ el kernel, con valores $k_{fila,columna}$:\n",
    "\n",
    "$$\n",
    "I =\n",
    "\\begin{bmatrix}\n",
    "p_{0,0} & p_{0,1} & \\cdots & p_{0,m} \\\\\n",
    "p_{1,0} & p_{1,1} & \\cdots & p_{1,m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "p_{n,0} & p_{n,1} & \\cdots & p_{n,m}\n",
    "\\end{bmatrix}, \\quad\n",
    "K =\n",
    "\\begin{bmatrix}\n",
    "k_{0,0} & k_{0,1} & k_{0,2} \\\\\n",
    "k_{1,0} & k_{1,1} & k_{1,2} \\\\\n",
    "k_{2,0} & k_{2,1} & k_{2,2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Se inicia recorriendo cada pixel $p$ de la imagen original, que es equivalente a recorrer una matriz. Para cada pixel primero se verifica si es un borde. Si es un borde, simplemente se ignora la iteración actual. Si no es un borde, se hace la convolución con el kernel para la región con centro en el píxel $p$ en la posición (i,j), es decir $p_{i,j}$. Para ello, se obtiene la submatriz $V$ 3x3, que representa el vecindario de pixeles de  $p_{i,j}$ en la imagen:\n",
    "\n",
    "$$\n",
    "V \\text{(submatriz 3x3 centrada en } p_{i,j}):\n",
    "\\quad\n",
    "\\begin{bmatrix}\n",
    "p_{i-1,j-1} & p_{i-1,j} & p_{i-1,j+1} \\\\\n",
    "p_{i,j-1} & p_{i,j} & p_{i,j+1} \\\\\n",
    "p_{i+1,j-1} & p_{i+1,j} & p_{i+1,j+1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "La convolución resultante para la posición para esa posición de pixel consiste en: multiplicar cada elemento del vecindario por el elemento correspondiente del kernel, y luego sumar todos los resultados:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "V * K = \\;&\n",
    "\\underbrace{p_{i-1,j-1} k_{0,0}}_{\\text{arriba izquierda}} +\n",
    "\\underbrace{p_{i-1,j} k_{0,1}}_{\\text{arriba centro}} +\n",
    "\\underbrace{p_{i-1,j+1} k_{0,2}}_{\\text{arriba derecha}} \\\\\n",
    "& + \\underbrace{p_{i,j-1} k_{1,0}}_{\\text{medio izquierda}} +\n",
    "\\underbrace{p_{i,j} k_{1,1}}_{\\text{centro}} +\n",
    "\\underbrace{p_{i,j+1} k_{1,2}}_{\\text{medio derecha}} \\\\\n",
    "& + \\underbrace{p_{i+1,j-1} k_{2,0}}_{\\text{abajo izquierda}} +\n",
    "\\underbrace{p_{i+1,j} k_{2,1}}_{\\text{abajo centro}} +\n",
    "\\underbrace{p_{i+1,j+1} k_{2,2}}_{\\text{abajo derecha}}\n",
    "\\end{align*}\n",
    "\n",
    "De manera más compacta, podemos escribir $V * K \\text{ como } sum(V \\odot K)$ donde $\\odot$ indica multiplicación elemento a elemento seguida de la suma de todos los elementos.\n",
    "\n",
    "Note que:\n",
    "\n",
    "$$\n",
    "V \\odot K =\n",
    "\\begin{bmatrix}\n",
    "p_{i-1,j-1} & p_{i-1,j} & p_{i-1,j+1} \\\\\n",
    "p_{i,j-1} & p_{i,j} & p_{i,j+1} \\\\\n",
    "p_{i+1,j-1} & p_{i+1,j} & p_{i+1,j+1}\n",
    "\\end{bmatrix}\n",
    "\\odot\n",
    "\\begin{bmatrix}\n",
    "k_{0,0} & k_{0,1} & k_{0,2} \\\\\n",
    "k_{1,0} & k_{1,1} & k_{1,2} \\\\\n",
    "k_{2,0} & k_{2,1} & k_{2,2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\begin{bmatrix}\n",
    "p_{i-1,j-1} k_{0,0} & p_{i-1,j} k_{0,1} & p_{i-1,j+1} k_{0,2} \\\\\n",
    "p_{i,j-1} k_{1,0} & p_{i,j} k_{1,1} & p_{i,j+1} k_{1,2} \\\\\n",
    "p_{i+1,j-1} k_{2,0} & p_{i+1,j} k_{2,1} & p_{i+1,j+1} k_{2,2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Finalmente, sumando todos los elementos obtenemos $sum(V \\odot K)$:\n",
    "\n",
    "\\begin{align*}\n",
    "V * K = \\;&\n",
    "\\underbrace{p_{i-1,j-1} k_{0,0}}_{\\text{arriba izquierda}} +\n",
    "\\underbrace{p_{i-1,j} k_{0,1}}_{\\text{arriba centro}} +\n",
    "\\underbrace{p_{i-1,j+1} k_{0,2}}_{\\text{arriba derecha}} \\\\\n",
    "& + \\underbrace{p_{i,j-1} k_{1,0}}_{\\text{medio izquierda}} +\n",
    "\\underbrace{p_{i,j} k_{1,1}}_{\\text{centro}} +\n",
    "\\underbrace{p_{i,j+1} k_{1,2}}_{\\text{medio derecha}} \\\\\n",
    "& + \\underbrace{p_{i+1,j-1} k_{2,0}}_{\\text{abajo izquierda}} +\n",
    "\\underbrace{p_{i+1,j} k_{2,1}}_{\\text{abajo centro}} +\n",
    "\\underbrace{p_{i+1,j+1} k_{2,2}}_{\\text{abajo derecha}}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "*Ejemplo de aplicación*\n",
    "\n",
    "En los **vehículos autónomos**, las convoluciones se utilizan para detectar objetos, como peatones, automóviles o semáforos.  \n",
    "- Cada filtro resalta diferentes características (bordes, texturas, colores).  \n",
    "- Las redes neuronales utilizan estos patrones para interpretar la escena y tomar decisiones.\n",
    "\n",
    "Puede ver el siguiente video para ver cómo las convoluciones ayudan en la conducción autónoma. Note que cada color separa a una entidad de cierto tipo, como personas, carros, semáforos, vegetación, etc: [Video de conducción autónoma](https://www.youtube.com/shorts/11SVfSAsaHo).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "*Kernel Sobel vertical*\n",
    "\n",
    "En este ejercicio se utilizará el **kernel de Sobel vertical**, que permite **detectar bordes verticales**. Su matriz es:\n",
    "\n",
    "```python\n",
    "[[-1, 0, 1],\n",
    "[-2, 0, 2],\n",
    "[-1, 0, 1]]\n",
    "```\n",
    "\n",
    "- Al aplicarlo, las zonas de la imagen con bordes verticales aparecerán más intensas en la imagen resultante.\n",
    "\n",
    "Este es un ejemplo de aplicar una convolución sobre una imagen, usando el kernel de sobel vertical:\n",
    "\n",
    "\n",
    "| Imagen original | Después de aplicar convolución con Sobel vertical |\n",
    "|-----------------|----------------|\n",
    "| <img src=\"https://raw.githubusercontent.com/EnriqueVilchezL/principios_de_info/main/10_computacion_numerica/imgs/capybara.png\" height=\"350px\"> | <img src=\"https://raw.githubusercontent.com/EnriqueVilchezL/principios_de_info/main/10_computacion_numerica/imgs/capybara-sobel.png\" height=\"350px\"> |\n",
    "\n",
    "*Pasos del ejercicio*\n",
    "\n",
    "Abajo se le proporcionan varias funciones ya hechas para:\n",
    "1. Leer una imagen desde su computadora y cargarla en colab. Puede utilizar esta imagen para probar si su algoritmo está correcto: [Imagen de capybara](https://raw.githubusercontent.com/EnriqueVilchezL/principios_de_info/main/10_computacion_numerica/imgs/capybara.png).\n",
    "2. Mostrar una imágen.\n",
    "3. Normalizar una imágen (hay que hacer que los valores de los pixeles resultantes de la convolución estén entre 0 y 255).\n",
    "\n",
    "Ya hay una celda de código que llama a todas estas funciones en orden para dejarla lista para ser procesada por un algoritmo de convolución.\n",
    "\n",
    "Existe una función de convolución que debería realizar la convolución entre una imágen y un kernel. Su trabajo es hacer el código que implementa el algoritmo de convolución dentro de esta función.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Leer la imagen como un np.ndarray\n",
    "    img = leer_imagen()\n",
    "    # Mostrar la imagen original\n",
    "    mostrar_imagen(img, titulo=\"Imagen original\")\n",
    "\n",
    "    # Aplicar el filtro de Sobel vertical\n",
    "    kernel_sobel_v = np.array(\n",
    "        [[-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]]\n",
    "    )\n",
    "    # Aplicar la convolución. Esta es la función que debe implementar.\n",
    "    img_sobel = convolucion2d(img, kernel_sobel_v)\n",
    "    # Normalizar la imagen resultante\n",
    "    img_sobel = normalizar(img_sobel)\n",
    "\n",
    "    # Mostrar la imagen con el filtro aplicado\n",
    "    mostrar_imagen(img_sobel, \"Sobel vertical\")\n",
    "    \n",
    "def leer_imagen() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Permite al usuario subir una imagen desde su computadora en Colab y la retorna como un arreglo numpy en escala de grises.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Arreglo numpy que representa la imagen en escala de grises.\n",
    "    \"\"\"\n",
    "    uploaded = files.upload()\n",
    "    if not uploaded:\n",
    "        print(\"No se subió ninguna imagen.\")\n",
    "        return None\n",
    "    file_name = next(iter(uploaded))\n",
    "    img = Image.open(io.BytesIO(uploaded[file_name])).convert('L')  # Escala de grises\n",
    "    return np.array(img)\n",
    "\n",
    "def mostrar_imagen(img: np.ndarray, titulo=\"Imagen\") -> None:\n",
    "    \"\"\"\n",
    "    Muestra una imagen en formato numpy usando matplotlib.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Arreglo numpy que representa la imagen.\n",
    "        titulo (str): Título de la imagen.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(titulo)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def normalizar(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normaliza los valores de una imagen para que estén en el rango [0, 255].\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Arreglo numpy que representa la imagen.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Imagen normalizada con valores en el rango [0, 255].\n",
    "    \"\"\"\n",
    "    img_abs = np.abs(img)\n",
    "    img_norm = (img_abs / img_abs.max()) * 255\n",
    "    img_norm = img_norm.astype(np.uint8)\n",
    "    return img_norm\n",
    "\n",
    "def convolucion2d(imagen: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Aplica la convolución 2D entre una imagen y un kernel.\n",
    "    El algoritmo básico es el siguiente:\n",
    "    1. Crear un arreglo de ceros con las mismas dimensiones que la imagen para almacenar el resultado\n",
    "    2. Recorrer cada pixel de la imagen (recorrer una matriz 2D) con dos ciclos for. Para cada pixel en la posición (i, j):\n",
    "        a. Verificar si el pixel es un borde o no\n",
    "            - Si es un borde, se ignora la iteración\n",
    "            - Si no es un borde:\n",
    "                - Obtener y almacenar en una variable una submatriz 3x3, que sea la region de pixeles vecinos del pixel actual, con el pixel actual siendo el centro de la matriz. Para ello, utilice operaciones de slicing en numpy.\n",
    "                - Multiplicar la region por el kernel (3x3), lo que resulta en una matriz 3x3.\n",
    "                - Sumar todos los elementos de la matriz 3x3 resultante y asignar el valor de la suma al pixel en la posición (i, j) del arreglo de ceros creado en el paso 2.\n",
    "    \n",
    "    Args:\n",
    "        imagen (np.ndarray): numpy array 2D (imagen en escala de grises)\n",
    "        kernel (np.ndarray): numpy array 2D (kernel de convolución)\n",
    "    Returns:\n",
    "        np.ndarray: Imagen resultante de la convolución.\n",
    "    \"\"\"\n",
    "    # Acá su código\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1784b",
   "metadata": {},
   "source": [
    "**Ejercicio 3**\n",
    "\n",
    "El algoritmo **k-Nearest Neighbors (kNN)** es uno de los métodos de **aprendizaje supervisado** más simples y no paramétricos utilizados para problemas de **clasificación** y **regresión**. Se basa en la idea de que los puntos de datos que están cerca en el espacio de características suelen tener propiedades o etiquetas similares.\n",
    "\n",
    "*¿Cómo funciona la Clasificación con kNN?*\n",
    "\n",
    "Para clasificar un nuevo punto de datos (el punto de consulta):\n",
    "\n",
    "1.  **Cálculo de Distancia:** Se calcula la distancia (típicamente euclidiana) entre el nuevo punto y **todos** los puntos de datos en el conjunto de entrenamiento.\n",
    "2.  **Identificación de Vecinos:** Se seleccionan los $k$ puntos de datos más cercanos, llamados los \"vecinos más cercanos\".\n",
    "3.  **Votación por Mayoría:** La etiqueta de clase del nuevo punto se asigna mediante una **votación por mayoría** entre esos $k$ vecinos. Es decir, se le asigna la clase que es más frecuente entre ellos.\n",
    "\n",
    "*Parámetro Clave: $k$*\n",
    "\n",
    "El valor de $k$ (el número de vecinos) es el único parámetro del modelo y es crucial:\n",
    "* Un **$k$ pequeño** (ej. $k=1$) hace que el modelo sea más sensible al ruido (sobreajuste).\n",
    "* Un **$k$ grande** suaviza la frontera de decisión, reduciendo el ruido pero aumentando la posibilidad de incluir puntos de otras clases (subajuste).\n",
    "\n",
    "---\n",
    "\n",
    "**Ejercicio Práctico: Clasificación Binaria de Frutas**\n",
    "\n",
    "Vamos a aplicar el algoritmo kNN para clasificar un nuevo objeto como una **\"Manzana\" (Clase 0)** o un **\"Kiwi\" (Clase 1)**, basándonos en dos características: **Peso (gramos)** y **Textura (suave=0, áspera=1)**.\n",
    "\n",
    "**Datos de Entrenamiento (Nuestros Vecinos)**\n",
    "\n",
    "| Fruta | Peso ($x_1$) | Textura ($x_2$) | Clase (y) |\n",
    "| :---: | :----------: | :-------------: | :-------: |\n",
    "| Fruta 1 | 150 | 0 (Suave) | 0 (Manzana) |\n",
    "| Fruta 2 | 160 | 0 (Suave) | 0 (Manzana) |\n",
    "| Fruta 3 | 120 | 1 (Áspera) | 1 (Kiwi) |\n",
    "| Fruta 4 | 130 | 1 (Áspera) | 1 (Kiwi) |\n",
    "\n",
    "**Punto de Consulta (El Misterio)**\n",
    "\n",
    "| Característica | Valor |\n",
    "| :------------: | :---: |\n",
    "| Peso ($x_1'$) | 145 |\n",
    "| Textura ($x_2'$) | 1 |\n",
    "\n",
    "---\n",
    "\n",
    "### **El Programa Requerido**\n",
    "\n",
    "Tiene crear un programa en Python que resuelva la clasificación utilizando la **Distancia Euclidiana** y el valor **$k=3$**.\n",
    "\n",
    "La fórmula para la **Distancia Euclidiana** entre un punto $P=(x_1, x_2)$ y un punto $Q=(x_1', x_2')$ es:\n",
    "\n",
    "$$\n",
    "d(P, Q) = \\sqrt{(x_1 - x_1')^2 + (x_2 - x_2')^2}\n",
    "$$\n",
    "\n",
    "**Implementación (Usando NumPy para operaciones vectorizadas):**\n",
    "\n",
    "1.  Crear una función `clasificar_knn(datos_entrenamiento, etiquetas, punto_consulta, k)` que reciba:\n",
    "    * `datos_entrenamiento`: Un arreglo 2D de NumPy con las características ($x_1$, $x_2$) de las frutas de entrenamiento.\n",
    "    * `etiquetas`: Un arreglo 1D de NumPy con las clases ($y$) de las frutas de entrenamiento.\n",
    "    * `punto_consulta`: Un arreglo 1D de NumPy con las características del punto a clasificar.\n",
    "    * `k`: El número de vecinos a considerar (debe ser $3$).\n",
    "2.  La función debe realizar los siguientes pasos (sin usar ciclos `for` o `while`):\n",
    "    * **Calcular Distancias:** Utilizar **operaciones vectorizadas de NumPy** para calcular la distancia euclidiana entre el `punto_consulta` y **todos** los puntos en `datos_entrenamiento`. Esto debe resultar en un arreglo 1D con las 4 distancias.\n",
    "    * **Obtener Índices de los Vecinos:** Obtener los **índices** de las $k$ distancias más pequeñas. La función `np.argsort` seguida de un *slicing* (`[:k]`) es la herramienta adecuada.\n",
    "    * **Identificar Etiquetas:** Usar los índices obtenidos para seleccionar las **etiquetas** correspondientes de los $k$ vecinos más cercanos.\n",
    "    * **Votación (Clasificación):** Determinar la clase final (0 o 1) contando cuál es la etiqueta más frecuente entre los $k$ vecinos. La función `np.bincount` puede ser útil para contar ocurrencias, y luego `np.argmax` para encontrar el índice (que es la clase) con el recuento más alto.\n",
    "    * **Retornar la Clase Asignada.**\n",
    "\n",
    "3.  En la función `main`, definir los arreglos de datos de entrenamiento y el punto de consulta, llamar a `clasificar_knn`, e imprimir el resultado de la clasificación.\n",
    "\n",
    "**NOTA:** Deberás **importar `numpy`** y resolver todo el cálculo de distancias y la identificación de vecinos sin utilizar **ciclos** explícitos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a17397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clasificar_knn(datos_entrenamiento: np.ndarray, etiquetas: np.ndarray, punto_consulta: np.ndarray, k: int) -> int:\n",
    "    \"\"\"\n",
    "    Clasifica un punto de consulta usando el algoritmo k-Nearest Neighbors (kNN).\n",
    "\n",
    "    Args:\n",
    "        datos_entrenamiento: Arreglo 2D de características (N_puntos, N_caracteristicas).\n",
    "        etiquetas: Arreglo 1D de etiquetas de clase (N_puntos).\n",
    "        punto_consulta: Arreglo 1D del punto a clasificar.\n",
    "        k: Número de vecinos a considerar.\n",
    "\n",
    "    Returns:\n",
    "        La clase asignada al punto de consulta (0 o 1).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Calcular Distancias Euclidianas (Vectorizado)\n",
    "    # Diferencia entre el punto de consulta y todos los puntos de entrenamiento\n",
    "    diferencia = datos_entrenamiento - punto_consulta\n",
    "    # Cuadrado de las diferencias\n",
    "    cuadrado_diferencia = diferencia**2\n",
    "    # Suma de los cuadrados a lo largo de las características (axis=1)\n",
    "    suma_cuadrados = np.sum(cuadrado_diferencia, axis=1)\n",
    "    # Raíz cuadrada para obtener la distancia euclidiana\n",
    "    distancias = np.sqrt(suma_cuadrados)\n",
    "    \n",
    "    # 2. Obtener Índices de los k Vecinos más Cercanos\n",
    "    # np.argsort devuelve los índices que ordenarían el arreglo.\n",
    "    # Tomamos los primeros 'k' para obtener los índices de las distancias más pequeñas.\n",
    "    indices_vecinos = np.argsort(distancias)[:k]\n",
    "    \n",
    "    # 3. Identificar Etiquetas de los k Vecinos\n",
    "    etiquetas_vecinos = etiquetas[indices_vecinos]\n",
    "    \n",
    "    # 4. Votación por Mayoría (Clasificación)\n",
    "    # np.bincount cuenta las ocurrencias de cada valor no negativo en el arreglo.\n",
    "    # np.argmax devuelve el índice del valor más alto (la clase más frecuente).\n",
    "    conteo_clases = np.bincount(etiquetas_vecinos)\n",
    "    clase_final = np.argmax(conteo_clases)\n",
    "    \n",
    "    return clase_final\n",
    "\n",
    "def main():\n",
    "    # Definición de las constantes y datos\n",
    "    K = 3 # Número de vecinos\n",
    "    \n",
    "    # Datos de Entrenamiento: [Peso, Textura]\n",
    "    datos_entrenamiento = np.array([\n",
    "        [150, 0],  # Manzana\n",
    "        [160, 0],  # Manzana\n",
    "        [120, 1],  # Kiwi\n",
    "        [130, 1]   # Kiwi\n",
    "    ])\n",
    "    \n",
    "    # Etiquetas de Entrenamiento: 0=Manzana, 1=Kiwi\n",
    "    etiquetas = np.array([0, 0, 1, 1])\n",
    "    \n",
    "    # Punto de Consulta: [Peso=145, Textura=1]\n",
    "    punto_consulta = np.array([145, 1])\n",
    "    \n",
    "    print(\"--- Clasificador kNN de Frutas ---\")\n",
    "    print(f\"Datos de Entrenamiento:\\n{datos_entrenamiento} (Etiquetas: {etiquetas})\")\n",
    "    print(f\"Punto a clasificar: {punto_consulta}\")\n",
    "    print(f\"Parámetro k: {K}\\n\")\n",
    "    \n",
    "    # Llamada a la función de clasificación\n",
    "    clase_asignada = clasificar_knn(datos_entrenamiento, etiquetas, punto_consulta, K)\n",
    "    \n",
    "    # Muestra de resultados\n",
    "    if clase_asignada == 0:\n",
    "        nombre_clase = \"Manzana!\"\n",
    "    else:\n",
    "        nombre_clase = \"Kiwi!\"\n",
    "        \n",
    "    print(f\"Resultado de la clasificación (k={K}):\")\n",
    "    print(f\"Clase Asignada (0=Manzana, 1=Kiwi): **{clase_asignada}**\")\n",
    "    print(f\"Conclusión: El punto {punto_consulta} se clasifica como **{nombre_clase}**.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ad158",
   "metadata": {},
   "source": [
    "**Ejercicio 1**\n",
    "\n",
    "El género de plantas **Iris**, cuyo nombre deriva de la palabra griega para **\"arcoíris\"**, es un género de plantas conocido por la impresionante y variada coloración de sus flores. Se encuentran en el hemisferio norte y han sido históricamente valoradas.\n",
    "\n",
    "*Anatomía Floral: Los Atributos de Medición*\n",
    "\n",
    "Con frecuencia, los botánicos clasifican los Iris para organizar su diversidad, entender su evolución, proteger las especies y usarlas mejor en ciencia y jardinería. Esta clasificación de las plantas se hace por especies. Es muy común que para clasificar una especie, los botánicos se centren en las mediciones de las siguientes dos estructuras fundamentales de la flor, que son las **características** o **atributos** que las diferencian más claramente entre especies:\n",
    "\n",
    "1.  **Sépalos (*Sepals*):** Las hojas modificadas externas que protegen el capullo.\n",
    "2.  **Pétalos (*Petals*):** Las estructuras internas, usualmente más vistosas y encargadas de atraer polinizadores.\n",
    "\n",
    "![Iris parts](https://raw.githubusercontent.com/EnriqueVilchezL/principios_de_info/main/11_manipulacion_de_archivos/imgs/iris.jpg)\n",
    "\n",
    "Nótese que cada tipo de especie tiene longitudes y anchos diferentes. Visualmente al menos se pueden diferenciar entre sí.\n",
    "\n",
    "---\n",
    "\n",
    "***El Dataset Iris: El Registro Botánico Estructurado***\n",
    "\n",
    "El **conjunto de datos Iris** es un registro de datos creado por el botánico Edgar Anderson y popularizado por el estadístico Ronald Fisher en 1936, en su artículo científico [The Use of Multiple Measurements in Taxonomic Problems](http://rcs.chemometrics.ru/Tutorials/classification/Fisher.pdf). \n",
    "\n",
    "El registro consta de un total de **150 observaciones** o **alistamientos** (filas), donde cada uno documenta una flor individual encontrada. Está guardado en un `.csv` generalmente, y tiene la siguiente forma:\n",
    "\n",
    "| sepal_length (cm) | sepal_width (cm) | petal_length (cm) | petal_width (cm) | species |\n",
    "| :---------------- | :--------------- | :---------------- | :--------------- | :------- |\n",
    "| 5.1 | 3.5 | 1.4 | 0.2 | Iris-setosa |\n",
    "| 4.9 | 3.0 | 1.4 | 0.2 | Iris-setosa |\n",
    "| 5.4 | 3.9 | 1.7 | 0.4 | Iris-setosa |\n",
    "| 6.4 | 3.2 | 4.5 | 1.5 | Iris-versicolor |\n",
    "| 5.5 | 2.3 | 4.0 | 1.3 | Iris-versicolor |\n",
    "| 6.3 | 3.3 | 6.0 | 2.5 | Iris-virginica |\n",
    "| 6.3 | 2.9 | 5.6 | 1.8 | Iris-virginica |\n",
    "| ... | ... | ... | ... | ... |\n",
    "| 6.5 | 3.0 | 5.8 | 2.2 | Iris-virginica |\n",
    "\n",
    "Cada una de estas filas es una planta individual resgitrada, que tiene anotada la longitud del sépalo (*sepal length*), ancho del sépalo (*sepal width*), longitud del pétalo (*petal length*), ancho del pétalo (*petal_width*) y la especie a la que pertenece (Iris-setosa, Iris-versicolor o Iris-virginica).\n",
    "\n",
    "Haga código python para resolver cada una de las siguientes tareas:\n",
    "1. Cargue el conjunto de datos de `iris.csv` en un Pandas `Dataframe`.\n",
    "2. Muestre en pantalla la cantidad de plantas de cada especie en el conjunto de datos.\n",
    "3. Muestre en pantalla la media, mediana, varianza y moda de las siguientes columnas:\n",
    "    - `sepal_length`\n",
    "    - `sepal_width`\n",
    "    - `petal_length`\n",
    "    - `petal_width`\n",
    "4. Cambie los valores de la columna `species` para que ahora sean datos numéricos. A esta operación se le llama `codificar`:\n",
    "    - Cambie el valor \"Iris-setosa\" por un 0.\n",
    "    - Cambie el valor \"Iris-versicolor\" por un 1.\n",
    "    - Cambie el valor \"Iris-virgnica\" por un 2.\n",
    "5. Guarde el `Dataframe` modificado en un nuevo archivo, llamado `iris-codificado.csv`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c431e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá su código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c3a224",
   "metadata": {},
   "source": [
    "**Ejercicio 1.1 (Continuación)**\n",
    "\n",
    "Un desafío común en la botánica es la identificación rápida de la especie. Los botánicos gastan mucho tiempo intentando clasificar la especie a la que pertenece una planta nueva, examinando datos como la longitud del sépalo (*sepal length*), ancho del sépalo (*sepal width*), longitud del pétalo (*petal length*), ancho del pétalo (*petal_width*).\n",
    "\n",
    "Así, el propósito del **dataset iris** es facilitar la vida a los botánicos, permitiendo la creación de un **programa informático** que clasifique **automáticamente la especie de una flor** (la **etiqueta**) basándose únicamente en los **cuatro valores de sus atributos** (sus mediciones).\n",
    "\n",
    "Esta es un área de la computación llamada **Aprendizaje Automático**. La idea es crear un algoritmo que utilice datos históricos para predecir atributos de nuevas observaciones. En este caso, se quiere predecir la especie de una planta dados sus cuatro características. Para esto, se va a usar el algoritmo **kNN**.\n",
    "\n",
    "---\n",
    "\n",
    "***El Algoritmo k-Nearest Neighbors (kNN)***\n",
    "\n",
    "El algoritmo **k-Nearest Neighbors (kNN)** es un método de **clasificación** simple, basado en la idea de que los objetos con atributos similares están cerca en el espacio de datos.\n",
    "\n",
    "*Funcionamiento en la Clasificación*\n",
    "\n",
    "Para determinar la especie de una flor desconocida (el punto de consulta):\n",
    "\n",
    "1.  **Medición de Distancia:** Se calcula la **distancia** (típicamente **Euclidiana**) entre el arreglo de atributos (un arreglo de 4 elementos, uno por cada medición de la planta) de la nueva flor y *cada* registro de flor en el dataset. Para ello, dada una nueva flor por clasificar $p$ que es un vector de 4 elementos, y un registro de flor $q$ en el dataset, se puede calcular la distancia entre ambos como:\n",
    "    $$\n",
    "    d(\\mathbf{p}, \\mathbf{q}) = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2}\n",
    "    $$\n",
    "\n",
    "![Euclidian distance](https://raw.githubusercontent.com/EnriqueVilchezL/principios_de_info/main/11_manipulacion_de_archivos/imgs/euclidiana.png)\n",
    "\n",
    "\n",
    "2.  **Selección de Vecinos ($k$):** Se identifican los **$k$ registros de flores más cercanos** (aquellos con la menor distancia).\n",
    "3.  **Votación por Mayoría:** La nueva flor hereda la **especie más frecuente** (la etiqueta más votada) entre esos $k$ vecinos.\n",
    "\n",
    "Si la clasificación dependiera solo de 2 variables o atributos, se podría visualizar en 2D:\n",
    "\n",
    "![kNN Gif](https://raw.githubusercontent.com/EnriqueVilchezL/principios_de_info/main/11_manipulacion_de_archivos/imgs/knn.gif)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
